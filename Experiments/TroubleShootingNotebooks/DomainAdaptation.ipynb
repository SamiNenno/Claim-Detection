{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(df):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    sentences = df.SENTENCE.to_list()\n",
    "    aug_en = naw.BackTranslationAug(from_model_name='Helsinki-NLP/opus-mt-de-en', to_model_name='Helsinki-NLP/opus-mt-en-de', device=device)\n",
    "    aug_sp = naw.BackTranslationAug(from_model_name='Helsinki-NLP/opus-mt-de-es', to_model_name='Helsinki-NLP/opus-mt-es-de', device=device)\n",
    "    en_augmented_data = aug_en.augment(sentences)\n",
    "    en_df = df.copy()\n",
    "    en_df.SENTENCE = en_augmented_data\n",
    "    sp_augmented_data = aug_sp.augment(sentences)\n",
    "    sp_df = df.copy()\n",
    "    sp_df.SENTENCE = en_augmented_data\n",
    "    augmentations = pd.concat([en_df, sp_df]).drop_duplicates('SENTENCE')\n",
    "    required_augmentation = 2600 if augmentations.shape[0] > 2600 else augmentations.shape[0]  # difference between 21st and 20th century\n",
    "    return pd.concat([df, augmentations.sample(n=required_augmentation, random_state=2022)]).drop_duplicates('SENTENCE').reset_index(drop=True)\n",
    "def doc_distributor(df, experiment):\n",
    "    frame = df[df[experiment].notna()].copy()\n",
    "    frame['label'] = frame[experiment]\n",
    "    frame['label'] = frame['label'].astype('int')\n",
    "    for doc_type in ['PROTOKOLL', 'SOCIAL_MEDIA', 'TALKSHOW', 'NEWSPAPER', 'MANIFESTO']:\n",
    "        print(f\"Test set is {doc_type}...\")\n",
    "        train = frame[frame.DOCUMENT_TYPE != doc_type]\n",
    "        test = frame[frame.DOCUMENT_TYPE == doc_type]\n",
    "        yield train, test, doc_type\n",
    "def topic_distributor(df, experiment):\n",
    "    frame = df[df[experiment].notna()].copy()\n",
    "    frame['label'] = frame[experiment]\n",
    "    frame['label'] = frame['label'].astype('int')\n",
    "    for topic in ['Impfpflicht', 'COP26', 'Zeitenwende']:\n",
    "        print(f\"Test set is {topic}...\")\n",
    "        train = frame[frame.TOPIC != topic]\n",
    "        test = frame[frame.TOPIC == topic]\n",
    "        yield train, test, topic\n",
    "def time_distributor(df, experiment):\n",
    "    frame = df[df[experiment].notna()].copy()\n",
    "    frame['label'] = frame[experiment]\n",
    "    frame['label'] = frame['label'].astype('int')\n",
    "    frame.DATE = frame.DATE.astype(str)\n",
    "    twenty = frame[frame.DATE.str.contains('1994|1995|1996|1997|1998')].drop_duplicates('SENTENCE')\n",
    "    twenty_one = frame[~frame.DATE.str.contains('1994|1995|1996|1997|1998')].drop_duplicates('SENTENCE')\n",
    "    for time in ['20th Century', '21st Century']:\n",
    "        print(f\"Test set is {time}...\")\n",
    "        if time == '20th Century':\n",
    "            yield twenty_one, twenty, time\n",
    "        else:\n",
    "            yield augmentation(twenty), twenty_one, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    def __init__(self, df, experiment, distributor, model_name:str, epochs:int = 5, batch_size:int=32):\n",
    "        self.transformer_dict = {\n",
    "        'Bert':'deepset/gbert-base',\n",
    "        'DistilBert':'distilbert-base-german-cased',\n",
    "        'GottBert': 'uklfr/gottbert-base',\n",
    "        'Electra': 'deepset/gelectra-base'}\n",
    "        self.df = df\n",
    "        self.experiment = experiment\n",
    "        self.distributor = distributor\n",
    "        self.model_name = model_name\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.result_dict = []\n",
    "        \n",
    "    def format_target(self, x):\n",
    "        k = ['PROTOKOLL', 'SOCIAL_MEDIA', 'TALKSHOW', 'NEWSPAPER', 'MANIFESTO', 'Impfpflicht', 'COP26', 'Zeitenwende', '20th Century', '21st Century']\n",
    "        v = ['Protocol', 'Twitter', 'Talkshow', 'Newspaper', 'Manifesto', 'Impfpflicht', 'COP26', 'Zeitenwende', '20th Century', '21st Century']\n",
    "        dct = {key:value for key, value in zip(k,v)}\n",
    "        return dct[x]\n",
    "\n",
    "    def tokenize_function(self, examples):\n",
    "            return self.tokenizer(examples[\"SENTENCE\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    def build_dataset(self, train_frame, test_frame):\n",
    "        train, test = Dataset.from_pandas(train_frame), Dataset.from_pandas(test_frame)\n",
    "        return train.map(self.tokenize_function, batched=True), test.map(self.tokenize_function, batched=True)  \n",
    "    \n",
    "    def fit(self):\n",
    "        idx = 0\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.transformer_dict[self.model_name])\n",
    "        self.num_labels = 4\n",
    "        self.training_args = TrainingArguments(output_dir=\"test_trainer\", \n",
    "                                               do_eval=False, \n",
    "                                               per_device_train_batch_size=self.batch_size, \n",
    "                                               num_train_epochs=self.epochs)\n",
    "        for train_df, test_df, target_split in self.distributor(self.df, self.experiment):\n",
    "            traindata, testdata = self.build_dataset(train_df, test_df)\n",
    "            #model = AutoModelForSequenceClassification.from_pretrained(self.transformer_dict[self.model_name], num_labels=self.num_labels)\n",
    "            #trainer = Trainer(model=model,args=self.training_args,train_dataset=traindata)\n",
    "            #trainer.train() \n",
    "            y_pred = np.random.randint(4, size=test_df.shape[0])#np.argmax(trainer.predict(testdata).predictions, axis=1)\n",
    "            y_true = test_df['label'].values\n",
    "            self.result_dict.append(dict(\n",
    "                Model = self.model_name,\n",
    "                Experiment = self.experiment,\n",
    "                Target_Split = target_split,\n",
    "                Train_Size = train_df.shape[0],\n",
    "                Test_Size = test_df.shape[0],\n",
    "                Accuracy = np.round(accuracy_score(y_true, y_pred),2),\n",
    "                F1 = np.round(f1_score(y_true, y_pred, average='weighted'),2),\n",
    "                Recall = np.round(recall_score(y_true, y_pred, average='weighted'),2),\n",
    "                Precision = np.round(precision_score(y_true, y_pred, average='weighted'),2)\n",
    "            ))\n",
    "            print(self.result_dict[idx])\n",
    "            idx += 1\n",
    "        self.results = pd.DataFrame(self.result_dict)\n",
    "        self.results.Target_Split = self.results.Target_Split.apply(lambda x: self.format_target(x))\n",
    "        return self.results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set is Impfpflicht...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.44ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.84ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'Impfpflicht', 'Train_Size': 4568, 'Test_Size': 805, 'Accuracy': 0.26, 'F1': 0.3, 'Recall': 0.26, 'Precision': 0.39}\n",
      "Test set is COP26...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.25ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.87ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'COP26', 'Train_Size': 4748, 'Test_Size': 625, 'Accuracy': 0.25, 'F1': 0.28, 'Recall': 0.25, 'Precision': 0.34}\n",
      "Test set is Zeitenwende...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.50ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.01ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'Zeitenwende', 'Train_Size': 4672, 'Test_Size': 701, 'Accuracy': 0.25, 'F1': 0.27, 'Recall': 0.25, 'Precision': 0.35}\n",
      "Test set is PROTOKOLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.69ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'PROTOKOLL', 'Train_Size': 3601, 'Test_Size': 1772, 'Accuracy': 0.26, 'F1': 0.26, 'Recall': 0.26, 'Precision': 0.29}\n",
      "Test set is SOCIAL_MEDIA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.12ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.74ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'SOCIAL_MEDIA', 'Train_Size': 3870, 'Test_Size': 1503, 'Accuracy': 0.25, 'F1': 0.27, 'Recall': 0.25, 'Precision': 0.31}\n",
      "Test set is TALKSHOW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.09ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.02ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'TALKSHOW', 'Train_Size': 4874, 'Test_Size': 499, 'Accuracy': 0.23, 'F1': 0.25, 'Recall': 0.23, 'Precision': 0.32}\n",
      "Test set is NEWSPAPER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.54ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.36ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'NEWSPAPER', 'Train_Size': 4189, 'Test_Size': 1184, 'Accuracy': 0.25, 'F1': 0.26, 'Recall': 0.25, 'Precision': 0.31}\n",
      "Test set is MANIFESTO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.83ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.57ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': 'MANIFESTO', 'Train_Size': 4967, 'Test_Size': 406, 'Accuracy': 0.27, 'F1': 0.28, 'Recall': 0.27, 'Precision': 0.32}\n",
      "Test set is 20th Century...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.43ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 13.59ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': '20th Century', 'Train_Size': 3984, 'Test_Size': 1384, 'Accuracy': 0.25, 'F1': 0.26, 'Recall': 0.25, 'Precision': 0.3}\n",
      "Test set is 21st Century...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.92ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.97ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DistilBert', 'Experiment': 'E0', 'Target_Split': '21st Century', 'Train_Size': 2691, 'Test_Size': 3984, 'Accuracy': 0.25, 'F1': 0.26, 'Recall': 0.25, 'Precision': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Target_Split</th>\n",
       "      <th>Train_Size</th>\n",
       "      <th>Test_Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Impfpflicht</td>\n",
       "      <td>4568</td>\n",
       "      <td>805</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>COP26</td>\n",
       "      <td>4748</td>\n",
       "      <td>625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Zeitenwende</td>\n",
       "      <td>4672</td>\n",
       "      <td>701</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Protocol</td>\n",
       "      <td>3601</td>\n",
       "      <td>1772</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>3870</td>\n",
       "      <td>1503</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Talkshow</td>\n",
       "      <td>4874</td>\n",
       "      <td>499</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Newspaper</td>\n",
       "      <td>4189</td>\n",
       "      <td>1184</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>Manifesto</td>\n",
       "      <td>4967</td>\n",
       "      <td>406</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>20th Century</td>\n",
       "      <td>3984</td>\n",
       "      <td>1384</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>E0</td>\n",
       "      <td>21st Century</td>\n",
       "      <td>2691</td>\n",
       "      <td>3984</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Experiment  Target_Split  Train_Size  Test_Size  Accuracy    F1  \\\n",
       "0  DistilBert         E0   Impfpflicht        4568        805      0.26  0.30   \n",
       "1  DistilBert         E0         COP26        4748        625      0.25  0.28   \n",
       "2  DistilBert         E0   Zeitenwende        4672        701      0.25  0.27   \n",
       "0  DistilBert         E0      Protocol        3601       1772      0.26  0.26   \n",
       "1  DistilBert         E0       Twitter        3870       1503      0.25  0.27   \n",
       "2  DistilBert         E0      Talkshow        4874        499      0.23  0.25   \n",
       "3  DistilBert         E0     Newspaper        4189       1184      0.25  0.26   \n",
       "4  DistilBert         E0     Manifesto        4967        406      0.27  0.28   \n",
       "0  DistilBert         E0  20th Century        3984       1384      0.25  0.26   \n",
       "1  DistilBert         E0  21st Century        2691       3984      0.25  0.26   \n",
       "\n",
       "   Recall  Precision  \n",
       "0    0.26       0.39  \n",
       "1    0.25       0.34  \n",
       "2    0.25       0.35  \n",
       "0    0.26       0.29  \n",
       "1    0.25       0.31  \n",
       "2    0.23       0.32  \n",
       "3    0.25       0.31  \n",
       "4    0.27       0.32  \n",
       "0    0.25       0.30  \n",
       "1    0.25       0.30  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sami/FLAIR/Data/Experiment_Frame.csv')\n",
    "experiment = 'E0'\n",
    "result_list = []\n",
    "for distributor in [topic_distributor, doc_distributor, time_distributor]:\n",
    "    transformer = Transformer(df = df,\n",
    "                              experiment=experiment,\n",
    "                              model_name='DistilBert',\n",
    "                              distributor=distributor\n",
    "                              )\n",
    "    result_list.append(transformer.fit())\n",
    "results = pd.concat(result_list)\n",
    "results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d013279ec9a42929aa5a6aee48384d90259723a5e75b817778f7a355b4aca79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
